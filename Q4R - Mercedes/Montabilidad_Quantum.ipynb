{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qiskit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantumCircuit\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aer, execute\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de archivos de datos\n",
    "1. Se importa como **'data'** el archivo de datos proporcionado. Los datos contienen los pedidos Train y Test a comparar. Se compararan todos los pedidos Train con los Test.\n",
    "   - Se descartan las columnas que no se utilizaran en la comparación.\n",
    "\n",
    "&nbsp;\n",
    "2. Se importa como **'data denominacion'** el archivo que contiene el nombre real de las piezas codificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('Montabilidad_to_Quantum.csv',delimiter=';', encoding='latin-1')\n",
    "data = pd.read_csv('Dataset_Quantum.csv',delimiter=',', encoding='latin-1')\n",
    "\n",
    "#columnas_a_quitar = ['file_type','metadata_path', 'metadata_date', 'metadata_size', 'query_key', 'text', 'Expediente', 'Código', 'N_Produccion', 'Fecha_Tecnica', 'metadata_file']\n",
    "columnas_a_quitar = ['Pedidos','Texto', 'Expediente', 'Codigo', 'N_Produccion']\n",
    "#data = data.drop(columnas_a_quitar, axis=1)\n",
    "data = data.drop(columnas_a_quitar, axis=1)\n",
    "\n",
    "data_denominacion = pd.read_excel('Codigos Denominacion 447.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se filtran en dos DataFrame diferentes los vectores Test y Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrado_vectores_train_test(data):\n",
    "    vectores_train = data[data['Set'] == 'Train']\n",
    "    vectores_test = data[data['Set'] == 'Test']\n",
    "    return (vectores_test, vectores_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para normalizar un vector:  módulo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_vector(vector):\n",
    "    norma = np.linalg.norm(vector)\n",
    "    return vector/norma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se le llama padding a la operación de rellenar un vector con 0s hasta llegar a un tamanño deseado.\n",
    "\n",
    "En este caso necesitamos rellenar los vectores de tal forma que correspondan a al tamaño $2^n$ para poder codificarlos en estados cuánticos. Siendo n el numerpo de qbits utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(vec, qubits):\n",
    "    num_componentes_relleno = 2**qubits - len(vec)\n",
    "    return np.pad(vec, (0, num_componentes_relleno), mode='constant', constant_values = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que calcula el producto interno de dos estados cuánticos. \n",
    "> **input:** 2 vectores normalizados.\n",
    "\n",
    "> **output:** producto interno. 0 si los vectores son totalmente diferentes 1 si son iguales.\n",
    "1. Se comprueba que los vectores tengan el mismo tamaño, se calcula el numero de qbits necesarios para la operación y se aplica el padding a los vectores.\n",
    "2. Se inicializan los estados cuánticos mediante la función initialize de Qiskit donde  los datos de los vectores se los codifica en amplitudes.\n",
    "3. Se realizan las mediciones sobre la base canónica mediante la matriz Z de Pauli. Se procesa el resultado para obtener el producto interno.\n",
    "\n",
    "La ejecución se hace sobre el simulador 'qasm_simulator'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_prod(vec1, vec2):\n",
    "\n",
    "    if len(vec1) != len(vec2):\n",
    "        raise ValueError('Lengths of states are not equal')\n",
    "\n",
    "    numero_componentes = len(vec1)\n",
    "    nqubits = math.ceil(np.log2(numero_componentes))\n",
    "\n",
    "    vec1 = padding(vec1, nqubits)\n",
    "    vec2 = padding(vec2, nqubits)\n",
    "\n",
    "    circ = QuantumCircuit(nqubits+1,1)\n",
    "    vec = np.concatenate([vec1,vec2])/np.sqrt(2)\n",
    "\n",
    "    circ.initialize(vec, range(nqubits+1))\n",
    "    circ.h(nqubits)\n",
    "    circ.measure(nqubits,0)\n",
    "\n",
    "    backend = Aer.get_backend('qasm_simulator')\n",
    "    job = execute(circ, backend, shots=20000)\n",
    "\n",
    "    result = job.result()\n",
    "    outputstate = result.get_counts(circ)\n",
    "\n",
    "    if ('0' in outputstate.keys()):\n",
    "        m_sum = float(outputstate[\"0\"])/20000\n",
    "    else:\n",
    "        m_sum = 0\n",
    "\n",
    "    inner_product = 2*m_sum-1\n",
    "    return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlacion_vectores(vector_1, vector_2):\n",
    "    test_normalizado = normalizar_vector(vector_1.iloc[ 1:-5].to_numpy())\n",
    "    train_normalizado = normalizar_vector(vector_2.iloc[ 1:-5].to_numpy())\n",
    "    return inner_prod(test_normalizado, train_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itera_por_matriz_cuantica(vectores_test, vectores_train):\n",
    "  for index_test, test in vectores_test.iterrows():\n",
    "    for index_train, train in vectores_train.iterrows():\n",
    "      correlacion_entre_variables = correlacion_vectores(test, train)\n",
    "      yield [f'test_{index_test}', f'train_{index_train}', correlacion_entre_variables, test['Categoria'], test['N_Pedido'],train['N_Pedido']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para obtener la difernecia de componentes entre el vector Test exótico y el Train similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diferencias_componentes(exotico, similar):\n",
    "    exotico = exotico.apply(lambda x: 1 if x != 0 else 0)\n",
    "    similar = similar.apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "    # Obtener las columnas que son 1 en `exotico` y 0 en `similar`\n",
    "    condicion1 = (exotico == 1) & (similar == 0)\n",
    "    diferencias_exotico = exotico[condicion1].index.tolist()\n",
    "\n",
    "    # Obtener las columnas que son 1 en `similar` y 0 en `exotico`\n",
    "    condicion2 = (similar == 1) & (exotico == 0)\n",
    "    diferencias_similar = similar[condicion2].index.tolist()\n",
    "    \n",
    "    return diferencias_exotico,diferencias_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_denominacion(comp, data_denominacion):\n",
    "    # Verifica si hay coincidencias\n",
    "    if comp in data_denominacion['Codigo'].values:\n",
    "        denominacion = data_denominacion[data_denominacion['Codigo'] == comp]['Denominación'].values[0]\n",
    "    else:\n",
    "        denominacion = 'No ha habido coincidencias'\n",
    "    return denominacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de creación del la tabla final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creacion_resultado_final( exotico, similar, diferencia_exotico, diferencia_similar):\n",
    "    # Crear el DataFrame\n",
    "    columnas = [\n",
    "        'Exotico',\n",
    "        'Tipo_Vehículo',\n",
    "        'Similar',\n",
    "        'Descripción',\n",
    "        'Componentes',\n",
    "        'Id',\n",
    "        'Categoria_exótico',\n",
    "        'Categoria_similar',\n",
    "        'Denominación'\n",
    "    ]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Iterar sobre la lista de diferencia exotico\n",
    "    for comp in diferencia_exotico:\n",
    "        entrada = [\n",
    "            exotico['N_Pedido'],\n",
    "            exotico['Tipo_vehiculo'],\n",
    "            similar['N_Pedido'],\n",
    "            'Componentes en el exotico que no aparecen en el similar',\n",
    "            'Mas',\n",
    "            comp,\n",
    "            exotico['Categoria'],\n",
    "            similar['Categoria'],\n",
    "            obtener_denominacion(comp, data_denominacion)\n",
    "        ]\n",
    "        data.append(entrada)\n",
    "\n",
    "    # Iterar sobre la lista de diferencia similar\n",
    "    for comp in diferencia_similar:\n",
    "        entrada = [\n",
    "            exotico['N_Pedido'],\n",
    "            exotico['Tipo_vehiculo'],\n",
    "            similar['N_Pedido'],\n",
    "            'Componentes en el similar que no aparecen en el exotico',\n",
    "            'Menos',\n",
    "            comp,\n",
    "            exotico['Categoria'],\n",
    "            similar['Categoria'],\n",
    "            obtener_denominacion(comp, data_denominacion)\n",
    "        ]\n",
    "        data.append(entrada)\n",
    "\n",
    "    # Crear el DataFrame final\n",
    "    return pd.DataFrame(data, columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados_csv(ruta_guardado, resultado, nombre_resultado):\n",
    "    # Comprobar si la ruta de guardado existe, si no, crearla\n",
    "    if not os.path.exists(ruta_guardado):\n",
    "        os.makedirs(ruta_guardado)\n",
    "\n",
    "    # Unir la ruta de guardado con el nombre del archivo y la extensión .csv\n",
    "    ruta_completa = os.path.join(ruta_guardado, f\"{nombre_resultado}.csv\")\n",
    "\n",
    "    # Guardar el DataFrame en el archivo CSV\n",
    "    resultado.to_csv(ruta_completa, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Nombre_Test', 'Nombre_Train', 'Correlacion', 'Categoria', 'N_Pedido_test', 'N_Pedido_train']\n",
    "categorias = data.groupby('Categoria')\n",
    "resultados_categorias = pd.DataFrame()\n",
    "\n",
    "for nom_categoria, categoria in categorias:\n",
    "    if nom_categoria != 'CLASE V':\n",
    "         vectores_test, vectores_train = filtrado_vectores_train_test(categoria) \n",
    "         \n",
    "         resultados_correlacion = pd.DataFrame(itera_por_matriz_cuantica(vectores_test, vectores_train), columns=columnas)\n",
    "         resultados_correlacion_ordenado = resultados_correlacion.sort_values(by='Correlacion')\n",
    "\n",
    "         \n",
    "\n",
    "         exotico = pd.Series(vectores_test[vectores_test['N_Pedido'] == resultados_correlacion_ordenado.iloc[0]['N_Pedido_test']].iloc[0])\n",
    "         \n",
    "         similar = resultados_correlacion[resultados_correlacion['N_Pedido_test'] == exotico['N_Pedido']].sort_values(by='Correlacion').iloc[-1]\n",
    "         train_similar = pd.Series(vectores_train[similar['N_Pedido_train'] == vectores_train['N_Pedido']].iloc[0])\n",
    "         \n",
    "         diferencias_exotico, diferencias_similar = diferencias_componentes(exotico.iloc[ :-4], train_similar.iloc[ :-4])\n",
    "\n",
    "         resultado = creacion_resultado_final(exotico, train_similar, diferencias_exotico, diferencias_similar)\n",
    "\n",
    "         resultados_categorias = pd.concat([resultados_categorias, resultado], ignore_index=True)\n",
    "         \n",
    "         display(resultados_correlacion_ordenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se asigna la etiqueta stuckliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stuckliste = pd.read_csv('TCU74A_Ibermatica.txt', delimiter=';', names = ['Serie','Pieza','Regla_Codigos','Fecha_hasta_validez_regla'])\n",
    "\n",
    "resultados_categorias['Stuckliste'] = resultados_categorias['Id'].apply(lambda x: 'X' if any(df_stuckliste['Regla_Codigos'].str.contains(x)) else '')\n",
    "resultados_categorias['Stuckliste'] = resultados_categorias['Id'].apply(lambda x: 'X' if any(df_stuckliste['Regla_Codigos'].str.contains(x)) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se asigna la etiqueta de chasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_categorias['Chasis'] = resultados_categorias['Exotico'].map(data.set_index('N_Pedido')['Chasis'].apply(lambda x: 'X' if pd.notna(x) and x.strip() != '' else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_guardado = 'Resultados\\Resultados_Categorias.csv'\n",
    "#nombre_resultado = 'Resultados_Categorias'\n",
    "resultados_categorias.to_csv(ruta_guardado, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
